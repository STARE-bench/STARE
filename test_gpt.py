import json
import yaml
import os
import time
from PIL import Image
from openai import OpenAI
import sys

# === æ·»åŠ æ¨¡å—è·¯å¾„ ===
sys.path.append("/mnt/petrelfs/gujiawei/stare_bench/release_stare/stare-bench")

# === å¯¼å…¥ç»„ä»¶ ===
from data_utils import build_query
from models.gpt import GPT_Model, create_message

# === è·¯å¾„é…ç½® ===
ROOT = "/mnt/petrelfs/gujiawei/stare_bench/release_stare"
JSONL_PATH = os.path.join(ROOT, "stare.jsonl")
CONFIG_PATH = os.path.join(ROOT, "stare-bench/configs/gpt.yaml")
IMAGE_ROOT = os.path.join(ROOT, "")

# === åŠ è½½ config.yaml ===
def load_yaml(path):
    with open(path, 'r') as f:
        return yaml.safe_load(f)

# === åŠ è½½ stare.jsonl çš„ç¬¬ä¸€æ¡æ ·æœ¬ ===
def load_first_sample(jsonl_path):
    with open(jsonl_path, 'r') as f:
        line = f.readline()
        return json.loads(line)

# === æ›¿æ¢è·¯å¾„ä¸º PIL.Image å¯¹è±¡ ===
def convert_image_paths_to_objects(sample, image_root):
    image_objs = []
    for img_path in sample['images']:
        full_path = os.path.join(image_root, img_path)
        try:
            image = Image.open(full_path).convert("RGB")
            image_objs.append(image)
        except Exception as e:
            print(f"âŒ Failed to load image: {full_path}\nError: {e}")
            image_objs.append(None)
    sample['images'] = image_objs
    return sample

# === ä¸»å‡½æ•° ===
if __name__ == "__main__":
    # Step 1: Load config & raw sample
    config = load_yaml(CONFIG_PATH)
    raw_sample = load_first_sample(JSONL_PATH)
    print(f"âœ… åŠ è½½ç¬¬ä¸€æ¡æ ·æœ¬: {raw_sample['qid']}")
    print(f"\nğŸ“ åŸå§‹é—®é¢˜å†…å®¹:\n{raw_sample['question']}")
    
    # Step 2: Load images as PIL.Image
    raw_sample = convert_image_paths_to_objects(raw_sample, IMAGE_ROOT)
    print(f"\nğŸ–¼ï¸ æˆåŠŸåŠ è½½å›¾åƒæ•°: {len(raw_sample['images'])}")

    # Step 3: Build query with <image> placeholders
    query_sample = build_query(raw_sample, config, strategy="Directly")
    print(f"\nğŸ“¦ æ„å»ºåçš„ query:\n{query_sample['query']}")
    print(f"\nâœ… æ­£ç¡®ç­”æ¡ˆ (gt_content): {query_sample['gt_content']}")

    # Step 4: æ„é€  messagesï¼ˆå¯é€‰æ‰“å°ï¼‰
    messages = create_message(query_sample)
    print("\nğŸ“¨ æ„é€ çš„ messagesï¼ˆç®€ç•¥å±•ç¤ºï¼‰:")
    for m in messages[0]['content']:
        if m['type'] == 'text':
            print("ğŸ”¹ TEXT:", m['text'][:60].replace('\n', ' ') + '...')
        else:
            print("ğŸ–¼ï¸ IMAGE: [base64 image embedded]")

    # Step 5: åˆå§‹åŒ– GPT æ¨¡å‹å¹¶è°ƒç”¨
    openai_client = OpenAI()  # ä»ç¯å¢ƒå˜é‡è¯»å– OPENAI_API_KEY
    gpt_model = GPT_Model(client=openai_client)

    print("\nğŸš€ è°ƒç”¨ GPT æ¨¡å‹ä¸­...")
    start_time = time.time()
    response = gpt_model.get_response(query_sample)
    end_time = time.time()

    # Step 6: æ‰“å°ç»“æœ
    print("\n=== ğŸ§  GPT é¢„æµ‹ç»“æœ ===\n")
    print(response)

    print("\n=== âœ… æ­£ç¡®ç­”æ¡ˆ (gt_content) ===\n")
    print(query_sample['gt_content'])

    print(f"\nâ±ï¸ æ¨ç†è€—æ—¶: {end_time - start_time:.2f} ç§’")
